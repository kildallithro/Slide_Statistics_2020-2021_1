{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e2cb44",
   "metadata": {},
   "source": [
    "# Week9 Multicollinearity-Ridge Regression\n",
    "## 背景描述  \n",
    "由于多重共线性的问题本质上在于 $|X^{'}X|\\approx 0$, 因此岭回归的本质就是在这个矩阵上做了手脚, 使得多重共线性的问题得到一定的缓解.  \n",
    "这里我们建立多元线性回归模型: $y=10+2*x_1+4*x_2+6*x_3+\\epsilon$, 我们人工给定 10 个值和 10 个满足正态分布的 $\\epsilon$, 使得其中 $x_2, x_3$ 具有强线性相关性.  \n",
    "由此我们构造了 10 个观测的 3 个变量，具体请见下表：\n",
    "\n",
    "## 数据描述\n",
    "| var | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n",
    "| :----------------: | :----------: | :----------: | :----------: | :----------: | :----------: | :----------: | :----------: | :----------: | :----------: | :----------: |\n",
    "| X1 | 1.5718740298258436 | 1.47315452346823 | 1.494091364549579 | 1.3649047118088795 | 1.919701805472498 | 1.4490605381137815 | 1.4977902773941874 | 1.830735451466069 | 1.7799850780870465 | 1.2193634132656626 |\n",
    "| X2 | 1.1 | 1.4 | 1.7 | 1.7 | 1.8 | 1.8 | 1.9 | 2 | 2.3 | 2.4 |\n",
    "| X3 | 1.1 | 1.5 | 1.8 | 1.7 | 1.9 | 1.8 | 1.8 | 2.1 | 2.4 | 2.5 |\n",
    "| $\\epsilon$ | -2.64878115 | 2.85013449 | 0.23311989 | -2.61284165 | 1.66706173 | 0.94808545 | -0.46825671 | -2.34017741 | 1.36687176 | 1.40009598 |\n",
    "| Y | 21.49496691 | 30.39644354 | 30.82130262 | 27.11696777 | 34.10646534 | 31.84620653 | 30.92732384 | 31.92129349 | 38.52684192 | 38.43882281 |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fca007",
   "metadata": {},
   "source": [
    "## 参数设置如下:   \n",
    "1. 样本量 n = 10\n",
    "2. 变量个数 p = 3\n",
    "3. 自变量 $x_1$ 的波动 $\\sigma_{x_1}=0.2$\n",
    "4. 误差的波动 $\\sigma_y=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbeb9d",
   "metadata": {},
   "source": [
    "## 问题\n",
    "1. 判断所给数据是否具有多重共线性.\n",
    "2. 若具有多重共线性, 选择适当的岭参数.\n",
    "3. 进行岭回归分析.\n",
    "\n",
    "\n",
    "## 解决方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60e42d",
   "metadata": {},
   "source": [
    "**Q1：**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310e80c",
   "metadata": {},
   "source": [
    "**仿真实验**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58395723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1    2    3          Y\n",
      "0  1.0  1.571874  1.1  1.1  21.494967\n",
      "1  1.0  1.473155  1.4  1.5  30.396444\n",
      "2  1.0  1.494091  1.7  1.8  30.821303\n",
      "3  1.0  1.364905  1.7  1.7  27.116968\n",
      "4  1.0  1.919702  1.8  1.9  34.106465\n"
     ]
    }
   ],
   "source": [
    "# Import standard packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Import additional packages\n",
    "from itertools import combinations\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import linear_model  # 进行岭回归分析\n",
    "from ipywidgets import interact  # 互动功能\n",
    "%matplotlib inline \n",
    "\n",
    "p = 3\n",
    "n = 10\n",
    "\n",
    "# 上帝视角下的beta: 截距项为 10，三个变量前的系数分别为 2，4,6\n",
    "beta = [10]\n",
    "for i in range(p):\n",
    "    beta.append((i+1)*2)\n",
    "beta = np.array(beta)\n",
    "# print(beta)\n",
    "\n",
    "# 构造 X 矩阵\n",
    "X = [[1.5718740298258436, 1.47315452346823, 1.494091364549579, 1.3649047118088795, 1.919701805472498, 1.4490605381137815, 1.4977902773941874, 1.830735451466069, 1.7799850780870465, 1.2193634132656626]]\n",
    "# X = np.random.normal(loc=1.5 , scale=0.2, size=(1,n)).tolist()\n",
    "X.append([1.1, 1.4, 1.7, 1.7, 1.8, 1.8, 1.9, 2, 2.3, 2.4])\n",
    "X.append([1.1, 1.5, 1.8, 1.7, 1.9, 1.8, 1.8, 2.1, 2.4, 2.5])\n",
    "X.insert(0, np.ones(n))\n",
    "X = np.array(X)\n",
    "X = X.T \n",
    "# print(X)\n",
    "\n",
    "# 生成 10 个满足正态分布的 epsilon 值\n",
    "epsilon = [-2.64878115, 2.85013449, 0.23311989, -2.61284165, 1.66706173, 0.94808545, -0.46825671, -2.34017741, 1.36687176, 1.40009598]\n",
    "# epsilon = np.random.normal(loc =0.0 , scale= 1, size = (1,n))\n",
    "# print(epsilon)\n",
    "\n",
    "# 上帝视角下的Y\n",
    "Y = X @ beta + epsilon\n",
    "# Y = X @ beta + epsilon[0] # 由于 np.random.normal 生成的列表中的元素仍是一个列表\n",
    "Y = Y.T\n",
    "# print(Y)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['Y'] = Y\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9067917",
   "metadata": {},
   "source": [
    "**对原始数据进行多元线性回归分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121e33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1603: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>0.00349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:42</td>     <th>  Log-Likelihood:    </th> <td> -19.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   46.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   47.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.9236</td> <td>    6.358</td> <td>    1.561</td> <td> 0.170</td> <td>   -5.634</td> <td>   25.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.6571</td> <td>    3.376</td> <td>    0.195</td> <td> 0.852</td> <td>   -7.602</td> <td>    8.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -7.1855</td> <td>   11.539</td> <td>   -0.623</td> <td> 0.556</td> <td>  -35.420</td> <td>   21.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   18.0735</td> <td>   10.866</td> <td>    1.663</td> <td> 0.147</td> <td>   -8.514</td> <td>   44.661</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.844</td> <th>  Durbin-Watson:     </th> <td>   2.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.656</td> <th>  Jarque-Bera (JB):  </th> <td>   0.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.297</td> <th>  Prob(JB):          </th> <td>   0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.889</td> <th>  Cond. No.          </th> <td>    77.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.881\n",
       "Model:                            OLS   Adj. R-squared:                  0.822\n",
       "Method:                 Least Squares   F-statistic:                     14.86\n",
       "Date:                Sat, 24 Apr 2021   Prob (F-statistic):            0.00349\n",
       "Time:                        23:28:42   Log-Likelihood:                -19.118\n",
       "No. Observations:                  10   AIC:                             46.24\n",
       "Df Residuals:                       6   BIC:                             47.45\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.9236      6.358      1.561      0.170      -5.634      25.481\n",
       "x1             0.6571      3.376      0.195      0.852      -7.602       8.917\n",
       "x2            -7.1855     11.539     -0.623      0.556     -35.420      21.049\n",
       "x3            18.0735     10.866      1.663      0.147      -8.514      44.661\n",
       "==============================================================================\n",
       "Omnibus:                        0.844   Durbin-Watson:                   2.539\n",
       "Prob(Omnibus):                  0.656   Jarque-Bera (JB):                0.661\n",
       "Skew:                          -0.297   Prob(JB):                        0.718\n",
       "Kurtosis:                       1.889   Cond. No.                         77.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= sm.OLS(Y, X).fit()\n",
    "Y_hat = model.fittedvalues\n",
    "beta_hat = model.params\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35402918",
   "metadata": {},
   "source": [
    "**对数据标准化:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c12258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1         2         3         Y\n",
      "0  1.0  0.017937 -0.615880 -0.619712 -0.669646\n",
      "1  1.0 -0.132022 -0.355649 -0.293548 -0.077394\n",
      "2  1.0 -0.100218 -0.095418 -0.048925 -0.049126\n",
      "3  1.0 -0.296457 -0.095418 -0.130466 -0.295591\n",
      "4  1.0  0.546299 -0.008674  0.032616  0.169449\n"
     ]
    }
   ],
   "source": [
    "# 对数据进行标准化\n",
    "# 自变量 X 的均值\n",
    "X_mean = []\n",
    "for i in range(p):\n",
    "    X_mean.append(np.mean(X[:, i+1])) \n",
    "\n",
    "# 自变量 X 的标准差\n",
    "X_L = []\n",
    "for i in range(p):\n",
    "    X_L.append(sum((X[:, i+1] - X_mean[i]) ** 2))  \n",
    "\n",
    "# 对自变量 X 标准化(截距项不用标准化)\n",
    "X_std = X * 1.0\n",
    "X_std[:,1:p+1] = (X[:,1:p+1] - X_mean) / np.sqrt(X_L)\n",
    "\n",
    "# 对因变量 Y 标准化\n",
    "Y_L = sum((Y - np.mean(Y))**2)\n",
    "Y_std = (Y - np.mean(Y)) / np.sqrt(Y_L)\n",
    "\n",
    "df_std = pd.DataFrame(X_std)\n",
    "df_std['Y'] = Y_std\n",
    "print(df_std.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29ee38",
   "metadata": {},
   "source": [
    "**对标准化后的数据进行多元线性回归分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cd76cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1603: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Apr 2021</td> <th>  Prob (F-statistic):</th>  <td>0.00349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:44</td>     <th>  Log-Likelihood:    </th> <td>  7.9824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>  -7.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>  -6.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.457e-16</td> <td>    0.044</td> <td> 3.28e-15</td> <td> 1.000</td> <td>   -0.109</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0288</td> <td>    0.148</td> <td>    0.195</td> <td> 0.852</td> <td>   -0.333</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.5511</td> <td>    0.885</td> <td>   -0.623</td> <td> 0.556</td> <td>   -2.717</td> <td>    1.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.4747</td> <td>    0.887</td> <td>    1.663</td> <td> 0.147</td> <td>   -0.695</td> <td>    3.644</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.844</td> <th>  Durbin-Watson:     </th> <td>   2.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.656</td> <th>  Jarque-Bera (JB):  </th> <td>   0.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.297</td> <th>  Prob(JB):          </th> <td>   0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.889</td> <th>  Cond. No.          </th> <td>    28.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.881\n",
       "Model:                            OLS   Adj. R-squared:                  0.822\n",
       "Method:                 Least Squares   F-statistic:                     14.86\n",
       "Date:                Sat, 24 Apr 2021   Prob (F-statistic):            0.00349\n",
       "Time:                        23:28:44   Log-Likelihood:                 7.9824\n",
       "No. Observations:                  10   AIC:                            -7.965\n",
       "Df Residuals:                       6   BIC:                            -6.755\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.457e-16      0.044   3.28e-15      1.000      -0.109       0.109\n",
       "x1             0.0288      0.148      0.195      0.852      -0.333       0.391\n",
       "x2            -0.5511      0.885     -0.623      0.556      -2.717       1.615\n",
       "x3             1.4747      0.887      1.663      0.147      -0.695       3.644\n",
       "==============================================================================\n",
       "Omnibus:                        0.844   Durbin-Watson:                   2.539\n",
       "Prob(Omnibus):                  0.656   Jarque-Bera (JB):                0.661\n",
       "Skew:                          -0.297   Prob(JB):                        0.718\n",
       "Kurtosis:                       1.889   Cond. No.                         28.1\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the multiple linear regression——对标准化后的数据\n",
    "model_std = sm.OLS(Y_std, X_std).fit()\n",
    "beta_std_hat = model_std.params\n",
    "Y_std_hat = model_std.fittedvalues\n",
    "model_std.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c34bf",
   "metadata": {},
   "source": [
    "**求 $(X^*)^{'}(X^*)$ 矩阵的特征值和特征向量:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050dbff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.059390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059390</td>\n",
       "      <td>0.985999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3\n",
       "1  1.000000  0.007981  0.059390\n",
       "2  0.007981  1.000000  0.985999\n",
       "3  0.059390  0.985999  1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (X*)'(X*) 矩阵等价于原始矩阵 X 样本相关矩阵\n",
    "R = df.corr()\n",
    "R = R.iloc[1:-1,1:-1]\n",
    "\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b16a7934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(R, cmap='Blues', annot=True) # annot: 在heatmap中每个方格写入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b9d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征值:  [0.9990421  1.9882966  0.01266129]\n"
     ]
    }
   ],
   "source": [
    "# 求特征值 & 特征向量\n",
    "W, V = np.linalg.eig(R)\n",
    "W_diag = np.diag(W)\n",
    "V = V.T # 这里需要转置\n",
    "print('特征值: ', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dcebd",
   "metadata": {},
   "source": [
    "**判断 X 矩阵是否具有多重共线性:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e496f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF方法判断结果(阈值为 5): \n",
      "设计矩阵 X 存在多重共线性.\n",
      "\n",
      "特征值判定法判断结果(阈值为 10): \n",
      "设计矩阵 X 存在多重共线性，其中kappa值为：12.5315\n"
     ]
    }
   ],
   "source": [
    "# 定义\"判断多重共线性\"的函数\n",
    "# 参数: (X_list: 设计矩阵 X, thres_vif: VIF 方法判断多重共线性的阈值, thres_kappa: 特征值方法判断多重共线性的阈值)\n",
    "def judge_col(X_list, thres_vif, thres_kappa): \n",
    "    var_num = X_list.shape[1]\n",
    "    print('VIF方法判断结果(阈值为 %d): '% thres_vif)\n",
    "    vif = [variance_inflation_factor(X_list, i) for i in range(var_num)]\n",
    "    for i in range(var_num):\n",
    "        if vif[i] >= thres_vif:\n",
    "            print('设计矩阵 X 存在多重共线性.')\n",
    "            break\n",
    "        elif i == var_num-1:\n",
    "            print('设计矩阵 X 不存在多重共线性.')\n",
    "\n",
    "    print('\\n特征值判定法判断结果(阈值为 %d): '% thres_kappa)\n",
    "    kappa = []\n",
    "    for i in range(var_num):\n",
    "        kappa.append(np.sqrt(max(W) / W[i]))\n",
    "    if np.max(kappa) >= thres_kappa:\n",
    "        print('设计矩阵 X 存在多重共线性，其中kappa值为：%.4f'% np.max(kappa))\n",
    "    else:\n",
    "        print('设计矩阵 X 不存在多重共线性，其中kappa值为：%.4f'% np.max(kappa))\n",
    "\n",
    "# 判断多重共线性\n",
    "X_std1 = X_std[:,1:p+1] # 将 X 矩阵的截距项去掉\n",
    "beta_std_hat1 = beta_std_hat[1:p+1] # 将 β_0 去掉 \n",
    "judge_col(X_std1, 5, 10) # 判断多重共线性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e581a7c",
   "metadata": {},
   "source": [
    "**Q2:**  \n",
    "岭参数 $k$ 选择(模型选择)的方法:   \n",
    "1. 岭迹法\n",
    "2. 方差扩大因子法\n",
    "3. 霍尔-肯纳德（Hoerl-Kennad）公式\n",
    "4. Mcdorard-Garaneau 公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b77161",
   "metadata": {},
   "source": [
    "1. 岭迹法  \n",
    "岭迹法的一般原则:   \n",
    "· 系数岭估计基本稳定;    \n",
    "· 最小二乘回归下符号不合理的回归系数, 在岭估计的意义下符号变得合理;    \n",
    "· 回归系数合乎经济意义;  \n",
    "· 残差平方和不会增大太多."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e347d259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903e23fd211c4a909accfc686a476167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='K', min=1), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.RR1(K=1)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0, 1) 范围内划分的最大精细程度: [0,0.01,0.02,...,0.99]\n",
    "range_const1 = 100\n",
    "\n",
    "def RR1(K = 1):\n",
    "    # 计算岭估计\n",
    "    rang1 = []\n",
    "    for i in range(K):\n",
    "        rang1.append(i/K) # 岭参数 k 取值范围: [0,1-1/K](例如 K=10, k 取值范围: [0, 0.9])\n",
    "    coefs_1 = []\n",
    "    for k in rang1:\n",
    "        temp1 = np.linalg.inv(X_std1.T @ X_std1 + k * np.eye(p)) @ X_std1.T @ Y_std\n",
    "        coefs_1.append(temp1)\n",
    "\n",
    "    # 画图\n",
    "    # print('参数的数值: ', coefs_1)\n",
    "    coefs_1 = np.array(coefs_1)\n",
    "    for i in range(p):\n",
    "        plt.plot(rang1, coefs_1[:,i], label = 'X%d'%(i+1))\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "# 随着 K 值的增加, 岭参数 k 取值越精细, 因为在 [0,1) 范围内的分割更细\n",
    "interact(RR1,K=(1,range_const1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ee912b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d4c6bf9a64479ab6ae53f117754b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='K', min=1), Output()), _dom_classes=('widget-interact',)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.RR2(K=1)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调包: linear_model \n",
    "def RR2(K = 1): \n",
    "    # 初始化一个Ridge Regression\n",
    "    clf = linear_model.Ridge(fit_intercept=False)\n",
    "\n",
    "    # 训练模型: 测试不同的 k 取值，获得系数\n",
    "    rang2 = []\n",
    "    for i in range(K):\n",
    "        rang2.append(i/K)\n",
    "    coefs_2 = []\n",
    "    for k in rang2:\n",
    "        clf.set_params(alpha=k)\n",
    "        clf.fit(X_std1, Y_std)\n",
    "        coefs_2.append(clf.coef_)\n",
    "\n",
    "    # 画图\n",
    "    # print('参数的数值: ', coefs_2)\n",
    "    coefs_2 = np.array(coefs_2)\n",
    "    for i in range(p):\n",
    "        plt.plot(rang2, coefs_2[:,i], label = 'X%d'%(i+1))   \n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "interact(RR2,K=(1,range_const1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dec7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c698f9faa774600847f5135835a65fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='K', max=30, min=1), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.RR3(K=1)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 岭参数 k 的最大取值范围: [exp(-10),exp(19)]\n",
    "range_const2 = 30\n",
    "\n",
    "def RR3(K = 1):\n",
    "    # 初始化一个Ridge Regression\n",
    "    clf = linear_model.Ridge(fit_intercept=False)\n",
    "    \n",
    "    # 训练模型: 测试不同的 k 取值，获得系数\n",
    "    coefs_3 = []\n",
    "    num_lambda3 = K\n",
    "    for k in range(num_lambda3):\n",
    "        clf.set_params(alpha=np.exp(k-10))  # 岭参数 k 取值范围: [exp(-10),exp((K-1)-10)]\n",
    "        clf.fit(X_std1, Y_std)\n",
    "        coefs_3.append(clf.coef_)\n",
    "\n",
    "    # 画图\n",
    "    # print('参数的数值：', coefs_3)\n",
    "    x3 = range(num_lambda3)\n",
    "    coefs_3 = np.array(coefs_3)\n",
    "    for i in range(p):\n",
    "        plt.plot(x3, coefs_3[:,i], label = 'X%d'%(i+1))\n",
    "        plt.text(x3[-1], coefs_3[-1,i], '%.4f' % float(coefs_3[-1,i]), fontsize=8)\n",
    "    print('岭参数为: ', np.exp(K-10))\n",
    "    print('对应的岭估计: ', coefs_3[-1,:])\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "interact(RR3,K=(1,range_const2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20430e0",
   "metadata": {},
   "source": [
    "基于交叉验证的岭回归 alpha 选择可以直接获得一个相对不错的 alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57046583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 的数值 :  0.1\n",
      "参数的数值： [0.06951731 0.32377326 0.55421425]\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个Ridge Cross-Validation Regression\n",
    "clf_cv = linear_model.RidgeCV(fit_intercept=False)\n",
    " \n",
    "# 训练模型\n",
    "clf_cv.fit(X_std1, Y_std)\n",
    "\n",
    "k_cv = clf_cv.alpha_\n",
    "coef_cv = clf_cv.coef_ \n",
    "print('k 的数值 : ', clf_cv.alpha_)\n",
    "print('参数的数值：', clf_cv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07871b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06951731 0.32377326 0.55421425]\n",
      "[0.06951731 0.32377326 0.55421425]\n",
      "差异:  [-1.83186799e-15 -4.44089210e-16 -1.88737914e-15]\n"
     ]
    }
   ],
   "source": [
    "# 验证岭估计和最小二乘估计之间的关系\n",
    "thres_k = int(k_cv * range_const1)\n",
    "print(coef_cv)\n",
    "\n",
    "C1 = X_std1.T @ X_std1\n",
    "C2 = np.linalg.inv(C1 + k_cv * np.eye(p))\n",
    "C3 = C2 @ C1\n",
    "print(C3 @ beta_std_hat1)\n",
    "\n",
    "diff = coef_cv - C3 @ beta_std_hat1\n",
    "print('差异: ', diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb50507",
   "metadata": {},
   "source": [
    "2. 方差扩大因子法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61ddaaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "岭参数为:  0.049787068367863944\n",
      "对应的岭估计:  [0.06766744 0.24318693 0.65651749]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefs_4 = []\n",
    "thres_vif = 5\n",
    "num_lambda4 = 30\n",
    "judge = True\n",
    "for k in range(num_lambda4):\n",
    "    cnt = 0\n",
    "    C = np.linalg.inv(C1 + np.exp(k-10) * np.eye(p)) @ C1 @np.linalg.inv(C1 + np.exp(k-10) * np.eye(p))\n",
    "    # print(k, C)\n",
    "    temp4 = np.linalg.inv(X_std1.T @ X_std1 + np.exp(k-10) * np.eye(p)) @ X_std1.T @ Y_std\n",
    "    coefs_4.append(temp4)\n",
    "    \n",
    "    # 给定 k, 使得所有方差扩大因子 C[j][j] <= thres_vif\n",
    "    for j in range(p):\n",
    "        if C[j][j] < thres_vif:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    if cnt == p:\n",
    "        k4 = np.exp(k-10)\n",
    "        print('岭参数为: ', np.exp(k-10))\n",
    "        print('对应的岭估计: ', temp4)\n",
    "        break\n",
    "\n",
    "# 画图\n",
    "coef_4 = temp4\n",
    "# print('参数的数值：', coefs_4)\n",
    "x4 = range(k+1)  # 以 k 作为横坐标\n",
    "# x4 = []  # 以 np.exp(k) 作为横坐标\n",
    "# for i in range(k+1):\n",
    "#      x4.append(np.exp(i-10))\n",
    "coefs_4 = np.array(coefs_4)\n",
    "for i in range(p):\n",
    "    plt.plot(x4, coefs_4[:,i], label = 'X%d'%(i+1))\n",
    "    plt.text(x4[-1], coefs_4[-1,i], '%.4f' % float(coefs_4[-1,i]), fontsize=8)\n",
    "\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20966665",
   "metadata": {},
   "source": [
    "3. 霍尔-肯纳德（Hoerl-Kennad）公式  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8543131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "岭参数 k_HK:  0.009654230925930096\n",
      "对应的岭估计:  [ 0.05095751 -0.11626096  1.03462265]\n"
     ]
    }
   ],
   "source": [
    "SSE = sum((Y_std - Y_std_hat) ** 2)\n",
    "sigma2 = SSE / (n - p - 1)\n",
    "\n",
    "Z = X_std1 @ V.T\n",
    "alpha_hat = np.linalg.inv(W_diag) @ Z.T @ Y_std\n",
    "# print(alpha_hat)\n",
    "\n",
    "k_HK = sigma2 / max(alpha_hat**2)\n",
    "k5 = k_HK\n",
    "print('岭参数 k_HK: ', k5)\n",
    "coef_5 = np.linalg.inv(X_std1.T @ X_std1 + k5 * np.eye(p)) @ X_std1.T @ Y_std\n",
    "print('对应的岭估计: ', coef_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd669b",
   "metadata": {},
   "source": [
    "4. Mcdorard-Garaneau 公式  \n",
    "如果 $Q=||\\hat{\\beta}||^2-\\hat{\\sigma}^2\\sum_{j=1}^p\\lambda_j^{-1} \\leq 0$，则认为 $\\hat{\\beta}$ 的各个分量都差不多，此时，对 $\\hat{\\beta}$ 不进行压缩，选择 $k = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62a3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  0.8881322270491734\n",
      "岭参数为:  0.01831563888873418\n",
      "对应的岭估计:  [0.05876355 0.0420594  0.87207132]\n"
     ]
    }
   ],
   "source": [
    "thres_diff = 0.2\n",
    "beta_compress = beta_std_hat1.T @ beta_std_hat1 - sigma2 * sum(1/W)\n",
    "if beta_compress <= 0:\n",
    "    k6 = 0\n",
    "    print('k = 0, 不对最小二乘估计进行压缩.')\n",
    "else:\n",
    "    print('Q: ', beta_compress)\n",
    "    coefs_6 = []\n",
    "    num_lambda6 = 30\n",
    "    for k in range(num_lambda6):\n",
    "        temp6 = np.linalg.inv(X_std1.T @ X_std1 + np.exp(k-10) * np.eye(p)) @ X_std1.T @ Y_std\n",
    "        beta_k_compress = temp6.T @ temp6\n",
    "        if abs(beta_compress-beta_k_compress) < thres_diff:\n",
    "            k6 = np.exp(k-10)\n",
    "            print('岭参数为: ', k6)\n",
    "            print('对应的岭估计: ', temp6)\n",
    "            break\n",
    "coef_6 = temp6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113acfa4",
   "metadata": {},
   "source": [
    "**Q3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56a1555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "岭参数 k =  0.1\n",
      "原始的最小二乘估计 =  [ 0.65713327 -7.18553507 18.07349643]\n",
      "标准化后的最小二乘估计 =  [ 0.02878265 -0.55114531  1.47472353]\n",
      "\n",
      "\n",
      "原始 beta =  [2 4 6]\n",
      "岭估计 =  [0.06951731 0.32377326 0.55421425]\n",
      "还原岭估计 =  [1.58714169 4.221181   6.79218113]\n"
     ]
    }
   ],
   "source": [
    "beta_rr = coef_cv\n",
    "print('岭参数 k = ', k_cv)\n",
    "print('原始的最小二乘估计 = ', beta_hat[1:p+1])\n",
    "print('标准化后的最小二乘估计 = ', beta_std_hat1)\n",
    "print('\\n')\n",
    "print('原始 beta = ', beta[1:p+1])\n",
    "print('岭估计 = ', beta_rr)\n",
    "print('还原岭估计 = ', beta_rr *  np.sqrt(Y_L) / np.sqrt(X_L))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af4e70",
   "metadata": {},
   "source": [
    "由此可知, 岭参数取值为 0.1 左右时，还原后的岭估计接近原始（上帝视角下）的 $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6edc3",
   "metadata": {},
   "source": [
    "## 第九周练习题 \n",
    "统计方法：Multicollinearity-Ridge Regression  \n",
    "软件：Jupyter Notebook  \n",
    "作业发到钉钉群  \n",
    "Deadline：下周一晚上10：00之前交  \n",
    "注：要有完整的解题过程，不能只有代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
